{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.stringutils import StringUtils\n",
    "from utils.logutils import LogUtils\n",
    "from utils.metafeatures import calculate_metafeatures, MetafeatureMapper\n",
    "\n",
    "from itertools import cycle, islice\n",
    "from sklearn import cluster, metrics, manifold, ensemble, model_selection, preprocessing\n",
    "import pandas as pd\n",
    "from sklearn import cluster, metrics, manifold, ensemble, model_selection, preprocessing\n",
    "from preprocess_data import PreprocessedDataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metafeatures\n",
    "tmp = pd.read_csv('/home/licari/AutoMLExperiments/autocluster/data/type=circles-k=2-n=1000-d=2-noise=0.0.csv')\n",
    "# Get all column names\n",
    "columns = tmp.columns\n",
    "\n",
    "# Assuming the last column is 'y_col' and all others are numeric\n",
    "file_dict = {\n",
    "    'numeric_cols': columns[:-1].tolist(),  # All columns except the last one\n",
    "    'categorical_cols': [],  # Assuming no categorical columns\n",
    "    'ordinal_cols': [],  # Assuming no ordinal columns\n",
    "    'y_col': columns[-1]  # The last column\n",
    "}\n",
    "# perform outlier detection\n",
    "preprocess_dict={}\n",
    "# No need to convert to numpy array here\n",
    "\n",
    "# Creating PreprocessedDataset object\n",
    "preprocessed_data = PreprocessedDataset(df=tmp, \n",
    "                                        y_col=columns[-1], \n",
    "                                        numeric_cols= columns[:-1].tolist(),\n",
    "                                        categorical_cols=[],\n",
    "                                        ordinal_cols=[],\n",
    "                                        ignore_cols=[])\n",
    "\n",
    "\n",
    "# Now you can get the numpy array if needed\n",
    "raw_data_np = preprocessed_data.X\n",
    "isolation_forest_contamination='auto'\n",
    "predicted_labels = ensemble.IsolationForest(n_estimators=100, \n",
    "                                                    warm_start=True,\n",
    "                                                    # behaviour='new',\n",
    "                                                    contamination=isolation_forest_contamination).fit_predict(raw_data_np)\n",
    "idx_np = np.where(predicted_labels == 1)\n",
    "        \n",
    "        # remove outliers\n",
    "raw_data_cleaned = tmp.iloc[idx_np].reset_index(drop=True)\n",
    "preprocess_dict['df'] = raw_data_cleaned\n",
    "columns=raw_data_cleaned.columns\n",
    "prepro_dict = {\n",
    "    'numeric_cols': columns[:-1].tolist(),  # All columns except the last one\n",
    "    'categorical_cols': [],  # Assuming no categorical columns\n",
    "    'ordinal_cols': [],  # Assuming no ordinal columns\n",
    "    'y_col': columns[-1]  # The last column\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/licari/AutoMLExperiments/autocluster/autocluster/utils/metafeatures.py:35: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return np.count_nonzero(X == None) + np.count_nonzero(X == '')\n",
      "/home/licari/AutoMLExperiments/autocluster/autocluster/utils/metafeatures.py:35: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return np.count_nonzero(X == None) + np.count_nonzero(X == '')\n",
      "/home/licari/AutoMLExperiments/autocluster/autocluster/utils/metafeatures.py:43: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return (np.count_nonzero(X == '') + np.count_nonzero(X == 0)) / X.size\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all available metafeatures\n",
    "metafeature_list = MetafeatureMapper.getAllMetafeatures()\n",
    "\n",
    "# Calculate all metafeatures\n",
    "metafeatures = calculate_metafeatures(raw_data_cleaned, prepro_dict, metafeature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('meta.csv')\n",
    "df2 = pd.read_csv('prova.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df2 to have only columns that are in df1\n",
    "df2_filtered = df2[df1.columns]\n",
    "\n",
    "# Concatenate df1 with the filtered df2\n",
    "result_df = pd.concat([df1, df2_filtered], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index(drop=True, inplace=True)\n",
    "result_df.to_csv('mf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autocluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
