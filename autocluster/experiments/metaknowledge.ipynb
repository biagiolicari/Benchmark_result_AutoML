{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pathlib\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# change directory\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import autocluster\n",
    "from autocluster import Decoder, LogHelper, LogUtils\n",
    "\n",
    "def test():\n",
    "\n",
    "    ##################################################################################################\n",
    "    # Define parameters for script                                                                   #\n",
    "    ##################################################################################################\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--log_filepath_ls\", default=[], nargs='+', type=str,\n",
    "                        help=\"List of log files to process.\")\n",
    "    parser.add_argument(\"--metafeatures_filename\", type=str, default='metafeatures_table', \n",
    "                        help=\"Name of metafeatures table (to be generated).\")\n",
    "    parser.add_argument(\"--datasets_dir\", default='datasets', type=str,\n",
    "                        help=\"Which folder does this metaknowledge belongs to?\")\n",
    "\n",
    "    config = parser.parse_args()\n",
    "\n",
    "##################################################################################################\n",
    "# Helper functions                                                                               #\n",
    "##################################################################################################\n",
    "\n",
    "def collect_and_save_metaknowledge(log_filepath_ls, \n",
    "                                   metafeatures_filename='metafeatures_table',\n",
    "                                   datasets_dir='datasets',\n",
    "                                   logger=None\n",
    "                                  ):\n",
    "    # logging function\n",
    "    def log(string):\n",
    "        if logger is None:\n",
    "            print(string)\n",
    "        else:\n",
    "            logger.info(string)\n",
    "    \n",
    "    # decode metaknowledge from log files\n",
    "    metadata = {}\n",
    "    for path in log_filepath_ls:\n",
    "        metadata.update(Decoder.decode_log_file(path=path))\n",
    "        \n",
    "    log(\"Metaknowledge extracted from following datasets: {}\".format(list(metadata.keys())))\n",
    "    \n",
    "    # magic stuff\n",
    "    is_primitive_or_none = lambda value: type(value) in (int, str, bool, float) or value is None\n",
    "    \n",
    "    # this thing will be turned into a dataframe later\n",
    "    metadata_ls = [\n",
    "        {k: v for k, v in metadata[d].items() if is_primitive_or_none(v)} for d in metadata\n",
    "    ]\n",
    "    \n",
    "    # get the set of all keys\n",
    "    allkeys = set().union(*metadata_ls)\n",
    "    \n",
    "    log(\"The metafeatures table will contain the following columns: {}\".format(allkeys))\n",
    "    \n",
    "    # fill None for missing keys\n",
    "    for d in metadata_ls:\n",
    "        missingkeys = allkeys.difference(set(d.keys()))\n",
    "        for k in missingkeys:\n",
    "            d[k] = None\n",
    "            \n",
    "    # save the metafeatures table\n",
    "    metafeatures_table = pd.DataFrame.from_dict(metadata_ls)\n",
    "    metafeatures_table.to_csv('{}/{}.csv'.format('metaknowledge', metafeatures_filename), \n",
    "                              encoding='utf-8', \n",
    "                              index=False)\n",
    "    \n",
    "    log(\"Saved metafeatures table as csv file.\")\n",
    "    \n",
    "    # create directory if doesn't exist\n",
    "    if not os.path.exists('metaknowledge/{}'.format(datasets_dir)):\n",
    "        pathlib.Path('metaknowledge/{}'.format(datasets_dir)).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # save the metaknowledge of each dataset as csv for retrieval of runhistory\n",
    "    for d in metadata:\n",
    "        string = json.dumps(metadata[d])\n",
    "        d_no_ext, _ = os.path.splitext(d)\n",
    "        print(string,  \n",
    "              file=open('{}/{}/{}.json'.format('metaknowledge', datasets_dir, d_no_ext), 'w'))\n",
    "        \n",
    "    log(\"Saved metaknowledge of each dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create output directory\n",
    "    output_dir = LogUtils.create_new_directory(prefix='metaknowledge_test')    \n",
    "\n",
    "    # Setup logger\n",
    "    LogHelper.setup(log_path='{}/meta.log'.format(output_dir), log_level=logging.INFO)\n",
    "    _logger = logging.getLogger(__name__)\n",
    "    _logger_path = logging.getLoggerClass().root.handlers[0].baseFilename\n",
    "    _logger.info(\"Log file location: {}\".format(_logger_path))\n",
    "    \n",
    "    # log all arguments passed into this script\n",
    "    _logger.info(\"Script arguments: {}\".format(vars(config)))\n",
    "    \n",
    "    # collect and save metaknowledge\n",
    "    collect_and_save_metaknowledge(log_filepath_ls=config.log_filepath_ls, \n",
    "                                   metafeatures_filename=config.metafeatures_filename,\n",
    "                                   datasets_dir=config.datasets_dir\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 17:48:40,093 INFO - autocluster.log_helper.log_helper - Finished configuring logger\n",
      "2023-11-23 17:48:40,103 INFO - __main__ - Log file location: /home/licari/AutoMLExperiments/autocluster/experiments/log/metaknowledge_test-2023-11-23_18-48-40-09215/meta.log\n"
     ]
    }
   ],
   "source": [
    "output_dir = LogUtils.create_new_directory(prefix='metaknowledge_test') \n",
    "# Setup logger\n",
    "LogHelper.setup(log_path='{}/meta.log'.format(output_dir), log_level=logging.INFO)\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger_path = logging.getLoggerClass().root.handlers[0].baseFilename\n",
    "_logger.info(\"Log file location: {}\".format(_logger_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metaknowledge extracted from following datasets: []\n",
      "The metafeatures table will contain the following columns: set()\n",
      "Saved metafeatures table as csv file.\n",
      "Saved metaknowledge of each dataset.\n"
     ]
    }
   ],
   "source": [
    "    # collect and save metaknowledge\n",
    "collect_and_save_metaknowledge(log_filepath_ls=[], \n",
    "                                   metafeatures_filename='metafeatures_table',\n",
    "                                   datasets_dir='./data/'\n",
    "                                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autocluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
